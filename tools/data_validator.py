#!/usr/bin/env python3
"""
æ•°æ®éªŒè¯å·¥å…·
ç”¨äºéªŒè¯ JSONL è®­ç»ƒæ•°æ®çš„æ ¼å¼å’Œè´¨é‡
"""

import json
import argparse
import os
from typing import Dict, List, Any
from collections import Counter
import re


class DataValidator:
    """JSONL æ•°æ®éªŒè¯å™¨"""
    
    def __init__(self, file_path: str):
        self.file_path = file_path
        self.errors = []
        self.warnings = []
        self.stats = {
            'total_lines': 0,
            'valid_docs': 0,
            'empty_lines': 0,
            'json_errors': 0,
            'missing_fields': 0,
            'duplicate_ids': 0,
            'text_lengths': [],
            'id_patterns': Counter(),
            'source_patterns': Counter()
        }
    
    def validate(self) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´çš„æ•°æ®éªŒè¯"""
        print(f"ğŸ” éªŒè¯æ•°æ®æ–‡ä»¶: {self.file_path}")
        print("=" * 50)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(self.file_path):
            self.errors.append(f"æ–‡ä»¶ä¸å­˜åœ¨: {self.file_path}")
            return self._generate_report()
        
        # éªŒè¯æ¯è¡Œæ•°æ®
        seen_ids = set()
        
        with open(self.file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                self.stats['total_lines'] += 1
                
                # è·³è¿‡ç©ºè¡Œ
                if not line.strip():
                    self.stats['empty_lines'] += 1
                    continue
                
                # éªŒè¯JSONæ ¼å¼
                try:
                    data = json.loads(line)
                except json.JSONDecodeError as e:
                    self.stats['json_errors'] += 1
                    self.errors.append(f"ç¬¬ {line_num} è¡Œ JSON è§£æé”™è¯¯: {e}")
                    continue
                
                # éªŒè¯æ•°æ®ç»“æ„
                validation_result = self._validate_document(data, line_num)
                if validation_result['valid']:
                    self.stats['valid_docs'] += 1
                    
                    # æ£€æŸ¥IDé‡å¤
                    doc_id = data['id']
                    if doc_id in seen_ids:
                        self.stats['duplicate_ids'] += 1
                        self.errors.append(f"ç¬¬ {line_num} è¡Œé‡å¤çš„ID: {doc_id}")
                    else:
                        seen_ids.add(doc_id)
                    
                    # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
                    self._collect_stats(data)
                else:
                    self.stats['missing_fields'] += 1
        
        # ç”ŸæˆæŠ¥å‘Š
        return self._generate_report()
    
    def _validate_document(self, data: Dict, line_num: int) -> Dict[str, Any]:
        """éªŒè¯å•ä¸ªæ–‡æ¡£çš„æ ¼å¼"""
        required_fields = ['id', 'text', 'source']
        missing_fields = []
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        for field in required_fields:
            if field not in data:
                missing_fields.append(field)
            elif not isinstance(data[field], str):
                self.warnings.append(f"ç¬¬ {line_num} è¡Œ '{field}' å­—æ®µåº”ä¸ºå­—ç¬¦ä¸²ç±»å‹")
            elif not data[field].strip():
                self.warnings.append(f"ç¬¬ {line_num} è¡Œ '{field}' å­—æ®µä¸ºç©º")
        
        if missing_fields:
            self.errors.append(f"ç¬¬ {line_num} è¡Œç¼ºå°‘å­—æ®µ: {', '.join(missing_fields)}")
            return {'valid': False, 'missing_fields': missing_fields}
        
        # æ£€æŸ¥æ–‡æœ¬é•¿åº¦
        text_length = len(data['text'])
        if text_length < 10:
            self.warnings.append(f"ç¬¬ {line_num} è¡Œæ–‡æœ¬è¿‡çŸ­ ({text_length} å­—ç¬¦)")
        elif text_length > 16384:
            self.warnings.append(f"ç¬¬ {line_num} è¡Œæ–‡æœ¬è¿‡é•¿ ({text_length} å­—ç¬¦)")
        
        # æ£€æŸ¥IDæ ¼å¼
        if not re.match(r'^[a-zA-Z0-9_-]+$', data['id']):
            self.warnings.append(f"ç¬¬ {line_num} è¡ŒIDåŒ…å«ç‰¹æ®Šå­—ç¬¦: {data['id']}")
        
        return {'valid': True}
    
    def _collect_stats(self, data: Dict):
        """æ”¶é›†æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        # æ–‡æœ¬é•¿åº¦ç»Ÿè®¡
        self.stats['text_lengths'].append(len(data['text']))
        
        # IDæ¨¡å¼ç»Ÿè®¡
        id_pattern = self._extract_pattern(data['id'])
        self.stats['id_patterns'][id_pattern] += 1
        
        # Sourceæ¨¡å¼ç»Ÿè®¡
        source_pattern = self._extract_pattern(data['source'])
        self.stats['source_patterns'][source_pattern] += 1
    
    def _extract_pattern(self, text: str) -> str:
        """æå–å­—ç¬¦ä¸²æ¨¡å¼"""
        # å°†æ•°å­—æ›¿æ¢ä¸ºNï¼Œå­—æ¯æ›¿æ¢ä¸ºA
        pattern = re.sub(r'\d+', 'N', text)
        pattern = re.sub(r'[a-zA-Z]+', 'A', pattern)
        return pattern
    
    def _generate_report(self) -> Dict[str, Any]:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        report = {
            'file_path': self.file_path,
            'validation_passed': len(self.errors) == 0,
            'stats': self.stats.copy(),
            'errors': self.errors.copy(),
            'warnings': self.warnings.copy()
        }
        
        # è®¡ç®—æ–‡æœ¬é•¿åº¦ç»Ÿè®¡
        if self.stats['text_lengths']:
            lengths = self.stats['text_lengths']
            report['stats']['text_length_stats'] = {
                'min': min(lengths),
                'max': max(lengths),
                'avg': sum(lengths) / len(lengths),
                'median': sorted(lengths)[len(lengths) // 2]
            }
        
        # æ‰“å°æŠ¥å‘Š
        self._print_report(report)
        
        return report
    
    def _print_report(self, report: Dict):
        """æ‰“å°éªŒè¯æŠ¥å‘Š"""
        stats = report['stats']
        
        print("\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"  æ€»è¡Œæ•°: {stats['total_lines']}")
        print(f"  æœ‰æ•ˆæ–‡æ¡£: {stats['valid_docs']}")
        print(f"  ç©ºè¡Œ: {stats['empty_lines']}")
        print(f"  JSONé”™è¯¯: {stats['json_errors']}")
        print(f"  ç¼ºå°‘å­—æ®µ: {stats['missing_fields']}")
        print(f"  é‡å¤ID: {stats['duplicate_ids']}")
        
        if 'text_length_stats' in stats:
            length_stats = stats['text_length_stats']
            print(f"\nğŸ“ æ–‡æœ¬é•¿åº¦ç»Ÿè®¡:")
            print(f"  æœ€çŸ­: {length_stats['min']} å­—ç¬¦")
            print(f"  æœ€é•¿: {length_stats['max']} å­—ç¬¦")
            print(f"  å¹³å‡: {length_stats['avg']:.0f} å­—ç¬¦")
            print(f"  ä¸­ä½æ•°: {length_stats['median']} å­—ç¬¦")
        
        # æ˜¾ç¤ºå¸¸è§æ¨¡å¼
        if stats['id_patterns']:
            print(f"\nğŸ” IDæ¨¡å¼ (å‰5ä¸ª):")
            for pattern, count in stats['id_patterns'].most_common(5):
                print(f"  {pattern}: {count} æ¬¡")
        
        if stats['source_patterns']:
            print(f"\nğŸ“ Sourceæ¨¡å¼ (å‰5ä¸ª):")
            for pattern, count in stats['source_patterns'].most_common(5):
                print(f"  {pattern}: {count} æ¬¡")
        
        # æ˜¾ç¤ºé”™è¯¯
        if report['errors']:
            print(f"\nâŒ é”™è¯¯ ({len(report['errors'])} ä¸ª):")
            for error in report['errors'][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªé”™è¯¯
                print(f"  {error}")
            if len(report['errors']) > 10:
                print(f"  ... è¿˜æœ‰ {len(report['errors']) - 10} ä¸ªé”™è¯¯")
        
        # æ˜¾ç¤ºè­¦å‘Š
        if report['warnings']:
            print(f"\nâš ï¸  è­¦å‘Š ({len(report['warnings'])} ä¸ª):")
            for warning in report['warnings'][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªè­¦å‘Š
                print(f"  {warning}")
            if len(report['warnings']) > 10:
                print(f"  ... è¿˜æœ‰ {len(report['warnings']) - 10} ä¸ªè­¦å‘Š")
        
        # éªŒè¯ç»“æœ
        print(f"\n{'=' * 50}")
        if report['validation_passed']:
            print("âœ… æ•°æ®éªŒè¯é€šè¿‡ï¼")
        else:
            print("âŒ æ•°æ®éªŒè¯å¤±è´¥ï¼Œè¯·ä¿®å¤ä¸Šè¿°é”™è¯¯åé‡è¯•ã€‚")
        
        # å»ºè®®
        print(f"\nğŸ’¡ å»ºè®®:")
        if stats['valid_docs'] < 1000:
            print("  - å»ºè®®è‡³å°‘æœ‰ 1000 ä¸ªæœ‰æ•ˆæ–‡æ¡£ä»¥è·å¾—æ›´å¥½çš„å‘é‡åŒ–æ•ˆæœ")
        if 'text_length_stats' in stats:
            avg_length = stats['text_length_stats']['avg']
            if avg_length < 100:
                print("  - æ–‡æ¡£å¹³å‡é•¿åº¦è¾ƒçŸ­ï¼Œå¯èƒ½å½±å“å‘é‡åŒ–è´¨é‡")
            elif avg_length > 8000:
                print("  - æ–‡æ¡£å¹³å‡é•¿åº¦è¾ƒé•¿ï¼Œå»ºè®®è€ƒè™‘åˆ†æ®µå¤„ç†")


def main():
    parser = argparse.ArgumentParser(description="éªŒè¯ JSONL è®­ç»ƒæ•°æ®æ ¼å¼")
    parser.add_argument("file_path", help="JSONL æ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", "-o", help="å°†éªŒè¯æŠ¥å‘Šä¿å­˜åˆ° JSON æ–‡ä»¶")
    
    args = parser.parse_args()
    
    # æ‰§è¡ŒéªŒè¯
    validator = DataValidator(args.file_path)
    report = validator.validate()
    
    # ä¿å­˜æŠ¥å‘Šï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ“„ éªŒè¯æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}")
    
    # è¿”å›é€‚å½“çš„é€€å‡ºç 
    exit(0 if report['validation_passed'] else 1)


if __name__ == "__main__":
    main()